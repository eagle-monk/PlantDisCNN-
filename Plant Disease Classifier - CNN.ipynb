{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1aac7-85fe-4a4e-9fae-c389d93c188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plant Disease Image Classifier - CNN\n",
    "\n",
    "# Set seeds for reproducability\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "import os\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# !pip install kaggle\n",
    "\n",
    "# Provide the full path to your kaggle.json file if it's not in the current directory\n",
    "kaggle_json_path = '/kaggle.json'  # Replace with the actual path\n",
    "\n",
    "# Load the Kaggle credentials\n",
    "kaggle_credentials = json.load(open(kaggle_json_path))\n",
    "\n",
    "# setting up the kaggle API key as env var\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_credentials['username']\n",
    "os.environ['KAGGLE_KEY'] = kaggle_credentials['key']\n",
    "\n",
    "!kaggle datasets download -d abdallahalidev/plantvillage-dataset\n",
    "\n",
    "# unzip the sownloaded dataset \n",
    "with ZipFile('plantvillage-dataset.zip', 'r') as zipObj:\n",
    "    zipObj.extractall()\n",
    "print(os.listdir('plantvillage dataset'))\n",
    "\n",
    "print(len(os.listdir('plantvillage dataset/segmented')))\n",
    "print(os.listdir('plantvillage dataset/segmented')[:5])\n",
    "\n",
    "print(len(os.listdir('plantvillage dataset/color')))\n",
    "print(os.listdir('plantvillage dataset/color')[:5])\n",
    "\n",
    "print(len(os.listdir('plantvillage dataset/grayscale')))\n",
    "print(os.listdir('plantvillage dataset/grayscale')[:5])\n",
    "\n",
    "print(len(os.listdir('plantvillage dataset/color/Grape___healthy')))\n",
    "print(os.listdir('plantvillage dataset/color/Grape___healthy')[:5])\n",
    "\n",
    "# Dataset Path\n",
    "base_dir = \"plantvillage dataset/color\"\n",
    "image_path = '/content/plantvillage dataset/color/Apple___Cedar_apple_rust/2770fd33-4612-4c09-80a7-dbac2ec8ff82___FREC_C.Rust 4049.JPG'\n",
    "\n",
    "# read the img\n",
    "img = mpimg.imread(image_path)\n",
    "\n",
    "print(img.shape)\n",
    "# display the img\n",
    "plt.imshow(img)\n",
    "plt.axis('off') # turn off axis numbers\n",
    "plt.show() \n",
    "\n",
    "image_path = '/content/plantvillage dataset/color/Apple___Cedar_apple_rust/2770fd33-4612-4c09-80a7-dbac2ec8ff82___FREC_C.Rust 4049.JPG'\n",
    "\n",
    "# read the img\n",
    "img = mpimg.imread(image_path)\n",
    "print(img)\n",
    "\n",
    "# img parameters\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "# img data generators\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ") # use 20% data for validation\n",
    "\n",
    "# train generator\n",
    "train_generator = data_gen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "# validation generator\n",
    "validation_generator = data_gen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "# model definition\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(38, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "# compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size, # no.s of steps per epoch\n",
    "    epochs=5, # no.s of epochs\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_generator.samples // batch_size # validation steps\n",
    ")\n",
    "# model evaluatoin\n",
    "print('Evaluating model...')\n",
    "test_loss, test_acc = model.evaluate(validation_generator, steps = validation_generator.samples//batch_size)\n",
    "print(f\"Test accuracy:, {test_acc*100:.3f}%\")\n",
    "\n",
    "# plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "# plot training and validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower left')\n",
    "\n",
    "# Fn to load and preprocess the img using PILLOW\n",
    "def load_and_preprocess_image(image_path, target_size = (224,224)):\n",
    "    img = Image.open(image_path) # load the img\n",
    "    img = img.resize(target_size) # resize the img\n",
    "    # Convert image to RGB if it has an alpha channel\n",
    "    if img.mode == 'RGBA':\n",
    "        img = img.convert('RGB')  \n",
    "    img_array = np.array(img) # convert the img to array\n",
    "    img_array = np.expand_dims(img_array, axis=0) # add batch dimension\n",
    "    img_array = img_array.astype('float32')/255.0\n",
    "    return img_array\n",
    "\n",
    "# fn to predict the class of an img\n",
    "def predict_img_class(model, image_path, class_indices):\n",
    "    preprocessed_array = load_and_preprocess_image(image_path) # Call load_and_preprocess_image to get the preprocessed image array\n",
    "    prediction = model.predict(preprocessed_array)\n",
    "    predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
    "    predicted_class_name = class_indices[predicted_class_index]\n",
    "    return predicted_class_name\n",
    "# creating a mapping form class indices to class names\n",
    "class_indices = {v: k for k, v in train_generator.class_indices.items()}\n",
    "\n",
    "# class_indices\n",
    "# saving the class names as json file\n",
    "json.dump(class_indices, open('class_indices.json', 'w'))\n",
    "\n",
    "# new example\n",
    "# image_path = \"/Screenshot 2025-05-13 010625.png\" # google\n",
    "# image_path = \"/Screenshot 2025-05-13 012800.png\" # google\n",
    "image_path = \"/content/plantvillage dataset/color/Corn_(maize)___Northern_Leaf_Blight/00a14441-7a62-4034-bc40-b196aeab2785___RS_NLB 3932.JPG\"\n",
    "predicted_class_name = predict_img_class(model, image_path, class_indices)\n",
    "print(f\"The predicted class is: {predicted_class_name}\") # output result\n",
    "\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc7cde-e78b-4a85-a6f7-5c44b98ae30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52550d53-6da1-4c53-92c8-ddfb71c1a806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725efff1-e1af-4b52-9c7e-2465658a7caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e75cfa1-a999-4096-9649-a5f4b4693972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\naray'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7794df-f431-45fc-998a-3b2abb60430f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7557af-b850-4e0c-b729-15b8d70f2a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318dff05-af7f-48e3-98a7-ee7a7e485a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd724d9-ef36-4c6f-bee2-f748dea873d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e5d7d-07a4-4c3b-b3ce-37cf2d2ca1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb55b72-eba9-444c-a721-7ef4c9bf8265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7857da57-6f53-4f7e-9e3e-63033ee81c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff75f60-812f-41c0-9afa-ad413c91f131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c53730-22b3-4093-ae5a-a69fa78f76d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34785a-df67-423d-b99b-ba03ec16e937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a4688-40b4-46f9-af84-0eabe7b6e42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ba5ea-23e5-4d66-9b3d-db0aa4789279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6f8db-b543-4a66-92c9-9ceae00e4f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee9750-f227-45b6-b653-b39f7a45ea4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27272fb2-f1d9-4820-9e4c-7d2708f6a76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49762a7d-1025-48d7-92af-3efc45633b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
